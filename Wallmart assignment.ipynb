{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Capstone Project - Walmart #\n",
    " Table of Contents\n",
    " 1. Problem Statement\n",
    " 2. Project Objective\n",
    " 3. Data Description\n",
    " 4. Data Pre-processing Steps and Inspiration\n",
    " 5. Choosing the Algorithm for the Project\n",
    " 6. Motivation and Reasons For Choosing the Algorithm\n",
    " 7. Assumptions\n",
    " 8. Model Evaluation and Techniques\n",
    " 9. Inferences from the Same\n",
    " 10. Future Possibilities of the Project\n",
    " 11. Conclusion\n",
    " 12. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Problem Statement\n",
    " # A retail store that has multiple outlets across the country are facing issues in managing the\n",
    " # inventory - to match the demand with respect to supply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Data Description\n",
    " # Data description, various insights from the data.\n",
    " # The Walmart DataSet.csv contains 6435 rows and 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1. You are provided with the weekly sales data for their various outlets. Use statistical\n",
    " analysis, EDA, outlier analysis, and handle the missing values to come up with various\n",
    " insights that can give them a clear perspective on the following:\n",
    "\n",
    " a. If the weekly sales are affected by the unemployment rate, if yes - which stores\n",
    " are suffering the most ?\n",
    " b. If the weekly sales show a seasonal trend, when and what could be the reason ?\n",
    " c. Does temperature affect the weekly sales in any manner ?\n",
    " d. How is the Consumer Price index affecting the weekly sales of various stores ?\n",
    " e. Top performing stores according to the historical data.\n",
    " f. The worst performing store, and how significant is the difference between the\n",
    " highest and lowest performing stores.\n",
    "\n",
    " 2. Use predictive modeling techniques to forecast the sales for each store for the next 12 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Data Preprocessing Steps And Inspiration\n",
    " The preprocessing of the data included the following steps:\n",
    " 1. First step to import the library.\n",
    " 2. Second step to read the data file Walmart DataSet.csv.\n",
    " 3. 45 different stores in this dataset.\n",
    " 4. Lets select the any store id from (1-45).\n",
    " 5. Check data inforamation & shape, duplicated, isnull etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    " import numpy as np\n",
    " import matplotlib.pyplot as plt\n",
    " import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m  \u001b[38;5;66;03m# There are about 45 different stores in this dataset. Lets select the any store id from 1-45\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m a\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the store id:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m store \u001b[38;5;241m=\u001b[39m data[data\u001b[38;5;241m.\u001b[39mStore \u001b[38;5;241m==\u001b[39m a]\n\u001b[0;32m      6\u001b[0m sales \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(store\u001b[38;5;241m.\u001b[39mWeekly_Sales\u001b[38;5;241m.\u001b[39mgroupby(store\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\bhakt\\Downloads\\Walmart(Project)\\Walmart (1).csv')\n",
    "data.set_index('Date', inplace=True)\n",
    " # There are about 45 different stores in this dataset. Lets select the any store id from 1-45\n",
    "a = int(input(\"Enter the store id:\"))\n",
    "store = data[data.Store == a]\n",
    "sales = pd.DataFrame(store.Weekly_Sales.groupby(store.index).sum())\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sales.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.duplicate().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['store'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # The objective of this project is to how can increase the sales day by day & reduce the losses.\n",
    " Analyze sales trends: By analyzing the weekly sales data for each store, we can identify the trends and patterns in \n",
    "sales over time. This information can help stores to adjust their inventory levels and plan for future sales more \n",
    "effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Total Weakly sales from all stores\n",
    " data['Weekly_Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #remove date from index to change its dtype because it clearly isnt acceptable.\n",
    " sales.reset_index(inplace = True)\n",
    " #converting 'date' column to a datetime type\n",
    " sales['Date'] = pd.to_datetime(sales['Date'])\n",
    " # resetting date back to the index\n",
    " sales.set_index('Date',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.Weekly_Sales.plot(figsize=(10,6), title= 'Weekly Sales of a Store', fontsize=14, color = 'blue')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    " decomposition = seasonal_decompose(sales.Weekly_Sales, period=12)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(12, 10)\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Understand the impact of holidays: The Holiday_Flag column in the dataset indicates whether a given week is a holiday week or not. Analyzing\n",
    " the sales data for holiday weeks vs. non-holiday weeks can help stores to understand the impact of holidays on their sales and plan accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the Algorithm For the Project\n",
    "To analyze sales trends using the weekly sales data for selected store, we can follow these steps:\n",
    " Load the Walmart dataset into a pandas dataframe.\n",
    " Convert the 'Date' column to a datetime format.\n",
    " Group the data by store and date, and calculate the total sales for each week.\n",
    " Pivot the data to create a table with stores as columns and weekly sales as rows.\n",
    " Plot the trend of sales for selected store.\n",
    " Plot the distribution of sales for selected store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #lets compare the 2012 data of two stores\n",
    " # Lets take store 5 data for analysis\n",
    " store5 = data[data.Store == 5]\n",
    " # there are about 45 different stores in this dataset.\n",
    " sales5 = pd.DataFrame(store5.Weekly_Sales.groupby(store5.index).sum())\n",
    " sales5.dtypes\n",
    " # Grouped weekly sales by store 6\n",
    " #remove date from index to change its dtype because it clearly isnt acceptable.\n",
    " sales5.reset_index(inplace = True)\n",
    " #converting 'date' column to a datetime type\n",
    " sales5['Date'] = pd.to_datetime(sales5['Date'])\n",
    " # resetting date back to the index\n",
    " sales5.set_index('Date',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=sales.Weekly_Sales\n",
    "y2=sales5.Weekly_Sales\n",
    " #y1['2012'].plot(figsize=(15, 6),legend=True, color = 'chocolate')\n",
    " #y2['2012'].plot(figsize=(15, 6), legend=True, color = 'turquoise')\n",
    " y1['2012'].plot(figsize=(15, 6),legend=True, color = 'Red')\n",
    " y2['2012'].plot(figsize=(15, 6), legend=True, color = 'Orange')\n",
    " plt.ylabel('Weekly Sales')\n",
    " plt.title('Store4 vs Store5 on 2012', fontsize = '16')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Choosing the Algorithm For the Project & Identify the impact of external  factors: \n",
    "\n",
    "The Temperature, Fuel_Price, CPI, and Unemployment columns in the dataset provide information about external factors \n",
    "that may impact sales. \n",
    "\n",
    "Analyzing the relationship between these factors and sales can help stores to better understand their customer base \n",
    "and adjust their inventory and pricing strategies accordingly.\n",
    "\n",
    "To identify the impact of external factors on sales using the Walmart dataset, we can follow these steps:\n",
    "\n",
    " Convert the 'Date' column to a datetime format.\n",
    "\n",
    " Plot the correlation matrix of the dataset to visualize the relationships between variables.\n",
    "\n",
    " Create scatter plots of the external factors against weekly sales to visualize the relationship between each factor \n",
    "and sales.\n",
    "\n",
    " Calculate the correlation coefficients between each external factor and weekly sales to quantify the strength of the \n",
    "relationship.\n",
    "\n",
    " Create a multiple regression model to analyze the impact of multiple external factors on weekly sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot the correlation matrix of the dataset\n",
    " corr = data.corr()\n",
    " sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    " plt.title('Correlation Matrix')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create scatter plots of external factors against weekly sales\n",
    " sns.pairplot(data[['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']])\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate the correlation coefficients between each external factor and weekly sales\n",
    " corr_sales = data[['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].corr()['Weekly_Sales']\n",
    " print(corr_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a multiple regression model to analyze the impact of multiple external factors on weekly sales\n",
    " X = data[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']]\n",
    " y = data['Weekly_Sales']\n",
    " model = LinearRegression().fit(X, y)\n",
    " r_sq = model.score(X, y)\n",
    " coefficients = model.coef_\n",
    " intercept = model.intercept_\n",
    " print(f\"R-squared: {r_sq}\")\n",
    " print(f\"Coefficients: {coefficients}\")\n",
    " print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Assumptions\n",
    " \n",
    "The following assumptions were made in order to create the model for Walmart project.\n",
    " \n",
    "This code generates several plots and prints out the correlation coefficients and regression coefficients:\n",
    " \n",
    "A plot of the correlation matrix of the dataset. This plot shows the strength and direction of the relationships \n",
    "between variables.\n",
    " \n",
    "A 2x2 grid of scatter plots showing the relationship between each external factor and weekly sales.\n",
    " \n",
    "The correlation coefficients between each external factor and weekly sales. These coefficients quantify the strength \n",
    "and direction of the relationship.\n",
    " \n",
    "The regression coefficients of a multiple regression model that analyzes the impact of multiple external factors on \n",
    "weekly sales. The R-squared value indicates the proportion of variance in weekly sales that can be explained by the \n",
    "external factors, and the coefficients indicate the strength and direction of the relationship between each factor \n",
    "and sales.\n",
    " The multiple regression model that was built to analyze the impact of external factors on weekly sales has an R\n",
    "squared value of 0.0243, which indicates that only 2.43% of the variance in weekly sales can be explained by the \n",
    "external factors in the model. This means that there are other factors that are not included in the model that also \n",
    "have an impact on sales.\n",
    " \n",
    "The coefficients of the model represent the strength and direction of the relationship between each external factor \n",
    "and weekly sales. The coefficients are as follows:\n",
    " \n",
    "Temperature: -885.67\n",
    " \n",
    "Fuel_Price: -12,248.42\n",
    " \n",
    "CPI: -1,585.82\n",
    " \n",
    "Unemployment: -41,214.99\n",
    " \n",
    "These coefficients indicate that an increase in temperature, fuel price, CPI, and unemployment is associated with a \n",
    "decrease in weekly sales.\n",
    " The intercept of the model is 1,743,607.62, which represents the estimated weekly sales when all external factors are \n",
    "at 0. This value is not particularly meaningful in this context because all external factors are unlikely to be 0 in \n",
    "real-world scenarios. However, it is still included in the model to account for the baseline level of weekly sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # analyzing Optimize pricing strategies: By analyzing the relationship \n",
    "increase sales.\n",
    " between sales and external factors such as CPI and Fuel_Price, stores \n",
    "can optimize their pricing strategies to attract more customers and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Filter the dataset to only include stores with holiday weeks\n",
    " data_holiday = data[data['Holiday_Flag'] == 1]\n",
    " # Create a scatter plot to visualize the relationship between weekly sales and CPI\n",
    " sns.scatterplot(x='CPI', y='Weekly_Sales', data=data_holiday)\n",
    " plt.title('Weekly Sales vs. CPI')\n",
    " plt.xlabel('CPI')\n",
    " plt.ylabel('Weekly Sales')\n",
    " plt.show()\n",
    " # Create a scatter plot to visualize the relationship between weekly sales and Fuel_Price\n",
    " sns.scatterplot(x='Fuel_Price', y='Weekly_Sales', data=data_holiday)\n",
    " plt.title('Weekly Sales vs. Fuel_Price')\n",
    " plt.xlabel('Fuel_Price')\n",
    " plt.ylabel('Weekly Sales')\n",
    " plt.show()\n",
    " # Build a linear regression model to predict weekly sales based on CPI and Fuel_Price\n",
    " X = data_holiday[['CPI', 'Fuel_Price']]\n",
    " y = data_holiday['Weekly_Sales']\n",
    " reg = LinearRegression().fit(X, y)\n",
    " # Print the coefficients of the linear regression model\n",
    " print('Coefficients:', reg.coef_)\n",
    " print('Intercept:', reg.intercept_)\n",
    " # Use the linear regression model to make predictions for different values of CPI and Fuel_Price\n",
    " new_data = pd.DataFrame({'CPI': [220, 230, 240], 'Fuel_Price': [3.50, 3.60, 3.70]})\n",
    " predictions = reg.predict(new_data)\n",
    " print('Predictions:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Model Evaluation and Technique\n",
    "The following techniques and steps were involved in the evaluation of the model\n",
    " 1. Technique 1 - coefficients\n",
    " 2. Technique 2 - linear regression model and  Predection model for Time Series so on.\n",
    " He coefficients of the linear regression model represent the change in weekly sales for a one-unit increase in each \n",
    "predictor variable, while holding all other variables constant.\n",
    " In this case, the first coefficient (-1194.64849703) represents the change in weekly sales for a one-unit increase in \n",
    "CPI, while holding Fuel_Price constant. The negative sign indicates that there is a negative correlation between CPI \n",
    "and weekly sales - as CPI increases, weekly sales tend to decrease. The magnitude of the coefficient (-1194.65) \n",
    "indicates the strength of the relationship.\n",
    " The second coefficient (46674.84850851) represents the change in weekly sales for a one-unit increase in Fuel_Price, \n",
    "while holding CPI constant. The positive sign indicates that there is a positive correlation between Fuel_Price and \n",
    "weekly sales - as Fuel_Price increases, weekly sales tend to increase. The magnitude of the coefficient (46674.85) \n",
    "indicates the strength of the relationship.\n",
    " The intercept (1176851.6465749654) represents the predicted weekly sales when both CPI and Fuel_Price are equal to \n",
    "zero.\n",
    " The predictions (\n",
    " [1077390.94700861, \n",
    "1070111\n",
    " .94688918, \n",
    "Regenerate response\n",
    " 1062832\n",
    " .94676976]) are the predicted weekly sales for new data \n",
    "points with different values of CPI and Fuel_Price, based on the coefficients of the linear regression model. For \n",
    "example, the first prediction (1077390.94700861) represents the predicted weekly sales for a new data point with a \n",
    "CPI of 220 and a Fuel_Price of 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Manage inventory levels: By analyzing sales trends and understanding \n",
    "the impact of holidays and external factors on sales, stores can adjust \n",
    "their inventory levels to better match the demand for their products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create a linear regression model to predict weekly sales\n",
    " X = data[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Holiday_Flag']]\n",
    " y = data['Weekly_Sales']\n",
    " model = LinearRegression().fit(X, y)\n",
    " # use the model to predict future sales\n",
    " future_data = pd.DataFrame({\n",
    " 'Temperature': [70, 75, 80],\n",
    " 'Fuel_Price': [3.5, 3.6, 3.7],\n",
    " 'CPI': [220, 222, 224],\n",
    " 'Unemployment': [6.0, 6.2, 6.4],\n",
    " 'Holiday_Flag': [0, 1, 0]\n",
    " })\n",
    " predicted_sales = model.predict(future_data)\n",
    " # adjust inventory levels based on predicted sales\n",
    " for i, predicted_sale in enumerate(predicted_sales):\n",
    " if predicted_sale > 100000:\n",
    " print(f\"Order more inventory for week {i+1}\")\n",
    " elif predicted_sale < 50000:\n",
    " print(f\"Reduce inventory for week {i+1}\")\n",
    " else:\n",
    " print(f\"Inventory levels are appropriate for week {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The evaluation report suggests the following:\n",
    " Inferences from the evaluation\n",
    "This code uses a linear regression model to predict future sales based on external factors such as temperature, fuel \n",
    "price, CPI, unemployment rate, and holiday flag. The model is trained on historical sales data and external factors, \n",
    "and then used to predict sales for future weeks.\n",
    "Based on the predicted sales, the code adjusts the inventory levels. If the predicted sales are high, the code \n",
    "recommends ordering more inventory. If the predicted sales are low, the code recommends reducing inventory levels. If \n",
    "the predicted sales are within an appropriate range, the code recommends maintaining current inventory levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Identify underperforming stores: By comparing the sales data across \n",
    "all stores, it may be possible to identify stores that are underperforming \n",
    "and take corrective action to improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total sales for each store\n",
    "store_sales = data.groupby('Store')['Weekly_Sales'].sum().reset_index()\n",
    " # calculate average sales per store\n",
    "avg_sales = store_sales['Weekly_Sales'].mean()\n",
    " # identify underperforming stores\n",
    "underperforming_stores = store_sales[store_sales['Weekly_Sales'] < avg_sales]\n",
    " # print the list of underperforming stores\n",
    "print(\"Underperforming stores:\")\n",
    "for store in underperforming_stores['Store']:\n",
    "    print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This code first groups the sales data by store and calculates the total sales for each store. It then calculates the \n",
    "average sales per store.\n",
    " \n",
    "Stores with total sales below the average are identified as underperforming stores. The code prints the list of \n",
    "underperforming stores.\n",
    " \n",
    "You can adjust the definition of underperforming stores by changing the criteria, for example, you could identify \n",
    "stores that have had decreasing sales over time or stores with low sales relative to their local market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Forecast future sales: By using the historical sales data, we can \n",
    "# develop prediction models to forecast sales for future weeks or months. \n",
    "# this can help stores to better plan for future sales and adjust their \n",
    "# inventory levels and pricing strategies accordingly.\n",
    "\n",
    " #Inferences from the Walmart Project\n",
    " The model performance, inferences, Forecast future sales, his can help stores to better plan for future sales and \n",
    "other details below -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly we can see the irregularities \n",
    "\n",
    " # Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 5)\n",
    "import itertools\n",
    "\n",
    " # Generate all different combinations of p, d and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    " # Generate all different combinations of seasonal p, d and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 52) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "mod = sm.tsa.statespace.SARIMAX(y1,\n",
    "                                    order=(4, 4, 3),\n",
    "                                    seasonal_order=(1, 1, 0, 52),   \n",
    "                                    enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-pastel')\n",
    "results.plot_diagnostics(figsize=(15, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forecasted = pred.predicted_mean\n",
    "y_truth = y1['2012-7-27':]\n",
    " # Compute the mean square error\n",
    "mse = ((y_forecasted - y_truth) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dynamic = results.get_prediction(start=pd.to_datetime('2012-7-27'), dynamic=True, full_results=True)\n",
    "pred_dynamic_ci = pred_dynamic.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y1['2010':].plot(label='observed', figsize=(12, 8))\n",
    "pred_dynamic.predicted_mean.plot(label='Dynamic Forecast', ax=ax)\n",
    "ax.fill_between(pred_dynamic_ci.index,\n",
    "pred_dynamic_ci.iloc[:, 0],\n",
    "pred_dynamic_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "ax.fill_betweenx(ax.get_ylim(), pd.to_datetime('2012-7-26'), y1.index[-1],\n",
    "alpha=.1, zorder=-1)\n",
    "ax.set_xlabel('Time Period')\n",
    "ax.set_ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " # Extract the predicted and true values of our time series\n",
    "y_forecasted = pred_dynamic.predicted_mean\n",
    "print(y_forecasted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truth = y1['2012-7-27':]\n",
    " \n",
    "print(y_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Future Possibilities\n",
    " \n",
    "The future possibilities, limitations and other\n",
    " \n",
    "This code first groups the sales data by store and date and calculates the total sales for each store on each date. \n",
    "It then converts the date column to a datetime format and splits the data into training and testing sets, with the \n",
    "training data being all dates before January 1, 2012 and the testing data being all dates on or after January 1, \n",
    "2012.\n",
    " \n",
    "A linear regression model is created using the store number as the predictor variable and the weekly sales as the \n",
    "response variable. The model is fit on the training data and used to make predictions on the testing data.\n",
    " \n",
    "The code then calculates the R-squared value, which measures the goodness of fit of the model to the testing data.\n",
    " \n",
    "You can adjust the model by using different predictor variables, such as the CPI, fuel price, or unemployment rate, \n",
    "or by using different models, such as a polynomial regression or a time series model.\n",
    "\n",
    "Predictions: [1376252.78477092 1376252.78477092 1376252.78477092 ... 729118.82756686 729118.82756686 729118.82756686] \n",
    "R-squared value: 0.1176607873663219\n",
    "\n",
    " The output is the predictions made by a model to forecast future sales based on historical sales data. The model has \n",
    "predicted the sales values for future weeks or months, and the R-squared value indicates how well the model fits the data.data\n",
    "\n",
    " An R-squared value of 0.1176607873663219 means that the model explains 11.77% of the variance in the data, which is \n",
    "relatively low. This suggests that the model may not be a good fit for the data, and further analysis may be \n",
    "necessary to improve the accuracy of the sales predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compute the Root mean square error\n",
    "rmse = np.sqrt(((y_forecasted - y_truth) ** 2).mean())\n",
    "print('The Root Mean Squared Error of our forecasts is {}'.format(round(rmse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residual= y_forecasted - y_truth\n",
    "print(\"Residual for Store1\",np.abs(Residual).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get forecast 12 weeks ahead in future\n",
    "pred_uc = results.get_forecast(steps=12)\n",
    "print(pred_uc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get confidence intervals of forecasts\n",
    "pred_ci = pred_uc.conf_int()\n",
    "ax = y1.plot(label='observed', figsize=(12, 8))\n",
    "pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "ax.fill_between(pred_ci.index,\n",
    "pred_ci.iloc[:, 0],\n",
    "pred_ci.iloc[:, 1], color='k', alpha=.25) ax.set_xlabel('Time Period')\n",
    "ax.set_ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Conclusion\n",
    "The Walmart project is good relation between each stores, sales effected when fuel price increase, tempers are \n",
    "increase- then sales decreased & seasonal, festival & offer provided by ... this time the sales increased.\n",
    " In future corelate the each another Walmart stores then incresed the sales and become decrised the costing, whereby \n",
    "income will be increasing day by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # References\n",
    "Some data downloaded & contantet copy form google and other resorces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
